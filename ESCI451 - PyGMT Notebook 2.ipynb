{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d0db698",
   "metadata": {},
   "source": [
    "# Plotting gridded data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1042db4",
   "metadata": {},
   "source": [
    "First up let's import PyGMT and some other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7b0cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygmt\n",
    "import pandas as pd\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddebc67",
   "metadata": {},
   "source": [
    "We are going to play around with some model output Simon Barker and colleagues worked up in their [paper](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018GC008152) on modeling ash dispersal from future eruptions of Taupō supervolcano.\n",
    "\n",
    "All the outputs from their models are included in an online repository, as any good, modern paper should! I have taken the liberty of including one model output in the data directory and we will start by playing with that, but you should explore the data repository and get other model outputs if you want.\n",
    "\n",
    "The output of the model is ash thickness, and is modeled dependent on a few things, including wind direction.\n",
    "\n",
    "Let's start by reading the data. The data is given in ESRI-ASCII format, which is used in GIS programmes like Arc. We've provided a function in `helpers` to convert this into a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc1e938",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.asc_to_df import transform_asc_to_df\n",
    "\n",
    "datafile = \"data/DepositFile_ESRI_ASCII.txt\"\n",
    "df = transform_asc_to_df(datafile)\n",
    "df.rename(columns={'variable':'thickness'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0753679a",
   "metadata": {},
   "source": [
    "Now let's draw a map and some contours of ash thickness. For the contouring we use the aptly named `contour` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f5775",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=pygmt.Figure()\n",
    "pygmt.config(MAP_FRAME_TYPE='plain', FORMAT_GEO_MAP='ddd.xx')\n",
    "fig.coast(region=[173,179,-42,-36],\n",
    "          shorelines=True,\n",
    "          land='lightgreen',\n",
    "          water='lightblue',\n",
    "          projection='M10c',\n",
    "          frame=['WSne','xa2f1','ya2f1'])\n",
    "\n",
    "fig.contour(x=df['longitude'],\n",
    "            y=df['latitude'],\n",
    "            z=df['thickness'],\n",
    "            levels=1, # draw a contour every 1mm thickness\n",
    "            annotation=10, # annotate every 10mm\n",
    "            pen='2p')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01cf3e0",
   "metadata": {},
   "source": [
    "That must have been a strong Westerly. Poor Gisbourne...\n",
    "\n",
    "There are really too many contours drawn there and it looks very messy. Let's tell PyGMT exactly which contours to plot. To do this we need to give the `levels` paramater a comma-seperated string of the contours we want. This isn't very pythonic, but hopefully this is improved in future versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5604395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=pygmt.Figure()\n",
    "pygmt.config(MAP_FRAME_TYPE='plain', FORMAT_GEO_MAP='ddd.xx')\n",
    "fig.coast(region=[173,179,-42,-36],\n",
    "          shorelines=True,\n",
    "          land='lightgreen',\n",
    "          water='lightblue',\n",
    "          projection='M10c',\n",
    "          frame=['WSne','xa2f1','ya2f1'])\n",
    "\n",
    "fig.contour(x=df['longitude'],\n",
    "            y=df['latitude'],\n",
    "            z=df['thickness'],\n",
    "            levels='1,5,10,15,20,25,30',\n",
    "            annotation='1,5,10,15,20,25,30',\n",
    "            pen='2p')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3d99c6",
   "metadata": {},
   "source": [
    "That's pretty easy and very handy for many earth science datasets. You can do something very similar with topography using the `grdcontour` module.\n",
    "\n",
    "Now, go and download a different model run from Simon's [repository](https://www.sciencebase.gov/catalog/item/5cdd9ed7e4b029273746367a) and plot it up:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0393c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8601216c",
   "metadata": {},
   "source": [
    "# Plotting Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a331aa68",
   "metadata": {},
   "source": [
    "Another common observation we deal with in Earth Science is vectors. PyGMT can handle these really nicely.\n",
    "\n",
    "For this exercise we're going to go down to Kaikōura and will begin by plotting an arbitrary vector with the `velo` module. We first have to out our data into a `dataframe` and then we plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c39f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=pygmt.Figure()\n",
    "pygmt.config(MAP_FRAME_TYPE='plain', FORMAT_GEO_MAP='ddd.xx')\n",
    "fig.coast(region=[172.5,174.5,-43,-41.5],\n",
    "          shorelines=True,\n",
    "          land='lightgreen',\n",
    "          water='lightblue',\n",
    "          projection='M10c',\n",
    "          frame=['WSne','xa0.5f0.1','ya0.5f0.1'])\n",
    "\n",
    "# Make a dataframe to store our data\n",
    "df = pd.DataFrame(data={\n",
    "        \"x\": [173.5],\n",
    "        \"y\": [-42],\n",
    "        \"east_velocity\": [3],\n",
    "        \"north_velocity\": [3],\n",
    "        })\n",
    "\n",
    "fig.velo(data=df,\n",
    "         pen='1p,black', # vector line\n",
    "         color='black', # arrow head\n",
    "         spec='e0.5/0.5', # this is telling it to plot a vector with a scale of 0.5 cm for each unit\n",
    "         )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a885a26",
   "metadata": {},
   "source": [
    "Ok great, but that vector doesn't mean anything. Let's do something more interesting.\n",
    "\n",
    "Let's begin by importing some GNSS data using the function from our previous notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf68e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import requests  # This helps with web-requests\n",
    "import datetime  # Python's representation of dates and times.\n",
    "\n",
    "\n",
    "# The following block of code defines a function that we can use\n",
    "# as often as we like to get GNSS data for a particular station\n",
    "def get_gnss_for_station(\n",
    "    station: str, \n",
    "    fits_url: str = \"http://fits.geonet.org.nz/observation\",) -> dict:\n",
    "    \"\"\"\n",
    "    Get GNSS data from GeoNet for the station\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    station\n",
    "        The name of the station you want to get data for\n",
    "    fits_url\n",
    "        URL of the FITS data service you want to query.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Dictionary with keys:\n",
    "        time \n",
    "            list of timestamps of observations\n",
    "        north\n",
    "            list of offsets in mm in the north direction\n",
    "        east\n",
    "            list of offsets in mm in the east direction\n",
    "        up          \n",
    "            list of vertical offsets in mm\n",
    "        north_error\n",
    "            list of errors in mm for north\n",
    "        east_error\n",
    "            list of errors in mm for east\n",
    "        up_error\n",
    "            list of erros in mm for up\n",
    "    \n",
    "    \"\"\"\n",
    "    # Initialise an empty dictionary that we will append to\n",
    "    out = dict(time=[],\n",
    "               north=[],\n",
    "               east=[],\n",
    "               up=[],\n",
    "               north_error=[],\n",
    "               east_error=[],\n",
    "               up_error=[])\n",
    "    for channel in {\"north\", \"east\", \"up\"}:\n",
    "        parameters = {\"typeID\": channel[0], \"siteID\": station}\n",
    "        response = requests.get(fits_url, params=parameters)\n",
    "        assert response.status_code == 200, \"Bad request\"\n",
    "        payload = response.content.decode(\"utf-8\").split(\"\\n\")\n",
    "        # payload is a csv with header\n",
    "        # This is a list-comprehension, a type of fast, one-line for loop\n",
    "        payload = [p.split(',') for p in payload]\n",
    "        # Check that this is what we expect\n",
    "        assert payload[0][0] == 'date-time', \"Unkown format\"\n",
    "        assert len(payload[0]) == 3, \"Unknown format\"\n",
    "        times, displacements, errors = zip(*[\n",
    "            (datetime.datetime.strptime(p[0], '%Y-%m-%dT%H:%M:%S.%fZ'),\n",
    "             float(p[1]), float(p[2])) for p in payload[1:-1]])\n",
    "        if len(out[\"time\"]) == 0:\n",
    "            out.update({\"time\": times})\n",
    "        else:\n",
    "            assert out[\"time\"] == times, \"Different time sampling for different components.\"\n",
    "        out.update({channel: displacements, f\"{channel}_error\": errors})\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e505ad",
   "metadata": {},
   "source": [
    "Let's use that to download some data from a Kaikōura GNSS station, remember you can see the map of GNSS stations [here](https://www.geonet.org.nz/data/gnss/map):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0374e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "GNSS_data = pd.DataFrame(get_gnss_for_station('KAIK'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf2f1b9",
   "metadata": {},
   "source": [
    "Nice, now let's have a look at that GNSS data either side of the Kaikōura earthquake. Remember this earthquake happened at 11:02:56 on 2016-11-13 (UTC time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a954f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for component in [\"north\", \"east\", \"up\"]:\n",
    "    ax.plot(GNSS_data[\"time\"], GNSS_data[component], \n",
    "            label=component)\n",
    "\n",
    "ax.set_xlim(pd.to_datetime('2016/11/06T11:02:56'), pd.to_datetime('2016/11/20T11:02:56')) # Calum is this the best way to be doing this?\n",
    "ax.set_xlabel(\"Sample time (UTC)\")\n",
    "ax.set_ylabel(\"Offset in mm\")\n",
    "ax.set_title(\"GNSS offsets for KAIK\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d63eb7",
   "metadata": {},
   "source": [
    "That's quite an offset! We could calculate a vector from that displacement\n",
    "\n",
    "Let's first cut our dataset down to the two week period we're interested in. We can do this by defining a filter and using the `loc` option in `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df8fefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_filter = (GNSS_data['time'] >= '2016/11/06T11:02:56') & (GNSS_data['time'] <= '2016/11/20T11:02:56')\n",
    "\n",
    "GNSS_data.loc[date_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f150d2",
   "metadata": {},
   "source": [
    "You can see that we've filtered our dataframe so that we now only have the data covering that two week period. Now to calculate the velocity over this time-window we simply need to calculate the difference between the north and east components at the beginning and end of this time period. Here's an example of how to do this for the North component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9da431",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_filter = (GNSS_data['time'] >= '2016/11/06T11:02:56') & (GNSS_data['time'] <= '2016/11/20T11:02:56')\n",
    "\n",
    "N_first_value = GNSS_data.loc[date_filter]['north'].first_valid_index()\n",
    "N_last_value = GNSS_data.loc[date_filter]['north'].last_valid_index()\n",
    "\n",
    "N_velo = N_last_value - N_first_value\n",
    "\n",
    "print(N_velo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea16fbf",
   "metadata": {},
   "source": [
    "Now here's an exercise. Calculate both the North and East velocity for this GNSS station and plot it as a vector on the map. To give you a hand I've given you some code to download the GNSS locations from GeoNet and an example of how to get the Latitude for KAIK:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72feee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the GNSS locations from GeoNet's GitHub\n",
    "url = (r'https://raw.githubusercontent.com/GeoNet/delta/main/network/marks.csv')\n",
    "sites = pd.read_csv(url, delimiter=\",\")\n",
    "sites.head()\n",
    "sites = sites.reset_index()\n",
    "\n",
    "site_lat = sites.loc[sites['Mark'] == 'KAIK']['Latitude']\n",
    "\n",
    "\n",
    "### Your answer here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fbc336",
   "metadata": {},
   "source": [
    "Great, now write a loop that downloads data and calculates vectors for the following nearby GNSS sites (MRBL, HANM, CMBL, WITH) and then plot them on a map.\n",
    "\n",
    "You could also plot the Kaikōura [epicentre](https://www.geonet.org.nz/earthquake/2016p858000):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7242742d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your answer here\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
